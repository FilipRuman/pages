---
title: 3. basic parser
description: parser
---
<p style="text-align: center;">  <a href="https://github.com/FilipRuman/RIP">GitHub </a> </p>

## Filtering useless tokens

We don't need all tokens, so let's filter them. Implement a function in main.rs that will filter out:

``TokenKind::Tab, TokenKind::Comment, TokenKind::WhiteSpace``


<details>
<summary> ⚠️ Implementation </summary>

``` rust
main.rs

fn parse() -> Result<()> {

    const FILE_PATH: &str = "test_files/test.c";

    let mut tokens = tokenize_file(FILE_PATH)
        .with_context(|| format!("tokenization of a file at path: '{FILE_PATH}'"))?;


    black_list_filter_tokens_by_kind(
        &mut tokens,
        HashSet::from([TokenKind::Tab, TokenKind::Comment, TokenKind::WhiteSpace]),
    );

    info!("Tokens: {tokens:#?}");

    Ok(())
}

fn black_list_filter_tokens_by_kind(tokens: &mut Vec<Token>, black_list: HashSet<TokenKind>) {
    tokens.retain(|token| !black_list.contains(&token.kind))
}
```


</details>

NEXT

<p style="text-align: center;">  <a href="https://github.com/FilipRuman/RIP">GitHub </a> </p>
